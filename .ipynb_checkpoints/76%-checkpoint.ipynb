{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3c9a038-c346-4b15-bc80-f6da792c2fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "FINAL OPTIMIZED 4-CLASS XGBOOST (BALANCED TRAINING + THRESHOLDING)\n",
      "===========================================================================\n",
      "\n",
      "Dataset: 1267 rows × 24 columns\n",
      "\n",
      "Merging KTAS classes 4 and 5 into a single class (4)...\n",
      "\n",
      "New Class Distribution:\n",
      "  KTAS 1:   26 (  2.1%)\n",
      "  KTAS 2:  220 ( 17.4%)\n",
      "  KTAS 3:  487 ( 38.4%)\n",
      "  KTAS 4:  534 ( 42.1%)\n",
      "\n",
      "===========================================================================\n",
      "TUNING XGBOOST FOR BEST OVERALL F1-SCORE\n",
      "===========================================================================\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "\n",
      "Best parameters found: {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.05, 'classifier__max_depth': 5, 'classifier__n_estimators': 400, 'classifier__subsample': 1.0, 'preprocessor__text__max_features': 250}\n",
      "\n",
      "Applying custom prediction threshold for KTAS 1...\n",
      "\n",
      "===========================================================================\n",
      "FINAL RESULTS (WITH THRESHOLD TUNING)\n",
      "===========================================================================\n",
      "\n",
      "Metric                    Score          \n",
      "----------------------------------------\n",
      "Accuracy                  0.7598 (75.98%)\n",
      "F1-Score (Weighted)       0.7569\n",
      "F1-Score (Macro)          0.7081\n",
      "\n",
      "===========================================================================\n",
      "CLASSIFICATION REPORT\n",
      "---------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      KTAS 1       0.75      0.60      0.67         5\n",
      "      KTAS 2       0.60      0.55      0.57        44\n",
      "      KTAS 3       0.77      0.74      0.76        98\n",
      "      KTAS 4       0.81      0.87      0.84       107\n",
      "\n",
      "    accuracy                           0.76       254\n",
      "   macro avg       0.73      0.69      0.71       254\n",
      "weighted avg       0.76      0.76      0.76       254\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "          Predicted KTAS\n",
      "Actual       1     2     3     4\n",
      "----------------------------------------\n",
      " KTAS 1  [3 2 0 0]\n",
      " KTAS 2  [ 1 24 12  7]\n",
      " KTAS 3  [ 0 10 73 15]\n",
      " KTAS 4  [ 0  4 10 93]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, make_scorer, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Keyword-based Feature Engineering Function ---\n",
    "def calculate_severity_score(text):\n",
    "    \"\"\"Enhanced keyword-based severity scoring\"\"\"\n",
    "    score = 0\n",
    "    text = str(text).lower()\n",
    "\n",
    "    critical = {\n",
    "        'arrest': 25, 'unconscious': 20, 'cpr': 25, 'hemorrhage': 18,\n",
    "        'infarction': 18, 'stroke': 20, 'seizure': 16, 'anaphylaxis': 18,\n",
    "        'shock': 20, 'paralysis': 18, 'hemiparesis': 16, 'code': 25\n",
    "    }\n",
    "    high = {\n",
    "        'dyspnea': 12, 'chest pain': 14, 'hematemesis': 13, 'melena': 12,\n",
    "        'syncope': 12, 'bleeding': 12, 'confusion': 13, 'acute': 11\n",
    "    }\n",
    "    moderate = {\n",
    "        'fever': 6, 'vomiting': 6, 'headache': 5, 'dizzy': 5, 'diarrhea': 5,\n",
    "        'laceration': 6, 'burn': 7, 'pain': 3, 'rash': 4\n",
    "    }\n",
    "    \n",
    "    for keyword, value in {**critical, **high, **moderate}.items():\n",
    "        if re.search(r'\\b' + re.escape(keyword) + r'\\b', text):\n",
    "            score += value\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Clinical feature engineering\"\"\"\n",
    "    \n",
    "    # Clean vitals\n",
    "    for col in ['SBP', 'DBP', 'HR', 'RR', 'Saturation', 'BT']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace(0, np.nan).fillna(df[col].median())\n",
    "    \n",
    "    # Derived vitals\n",
    "    df['shock_index'] = df['HR'] / (df['SBP'] + 1)\n",
    "    df['map'] = (df['SBP'] + 2 * df['DBP']) / 3\n",
    "    df['pulse_pressure'] = df['SBP'] - df['DBP']\n",
    "    \n",
    "    # Count abnormal vitals\n",
    "    df['abnormal_vitals'] = (\n",
    "        ((df['SBP'] < 90) | (df['SBP'] > 180)) +\n",
    "        ((df['HR'] < 50) | (df['HR'] > 120)) +\n",
    "        ((df['RR'] < 10) | (df['RR'] > 24)) +\n",
    "        (df['Saturation'] < 92) +\n",
    "        ((df['BT'] < 36) | (df['BT'] > 38.5))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Interactions\n",
    "    df['severity_x_pain'] = df['severity_score'] * np.log1p(df['NRS_pain'])\n",
    "    df['severity_x_mental'] = df['severity_score'] * (df['Mental'] != 1).astype(int)\n",
    "    df['age_x_severity'] = (df['Age'] / 100) * df['severity_score']\n",
    "    \n",
    "    # Age risk\n",
    "    df['high_risk_age'] = ((df['Age'] < 2) | (df['Age'] > 70)).astype(int)\n",
    "    \n",
    "    # Pain categories\n",
    "    df['high_pain'] = (df['NRS_pain'] >= 7).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Custom Prediction Function with Thresholds ---\n",
    "def predict_with_thresholds(probabilities, custom_thresholds):\n",
    "    \"\"\"\n",
    "    Applies custom thresholds to probabilities for prediction.\n",
    "    Class 0 (KTAS 1) is checked first.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    for prob_row in probabilities:\n",
    "        # Check high-priority classes first\n",
    "        if prob_row[0] >= custom_thresholds.get(0, 0.5): # Check for KTAS 1 (index 0)\n",
    "            preds.append(0)\n",
    "        else:\n",
    "            # If no custom threshold is met, predict the class with the highest probability\n",
    "            preds.append(np.argmax(prob_row))\n",
    "    return np.array(preds)\n",
    "\n",
    "\n",
    "# --- Main ---\n",
    "try:\n",
    "    print(\"=\"*75)\n",
    "    print(\"FINAL OPTIMIZED 4-CLASS XGBOOST (BALANCED TRAINING + THRESHOLDING)\")\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    df = pd.read_csv(r\"C:\\DATASETS\\triage\\data.csv\", delimiter=';', encoding='windows-1254')\n",
    "    print(f\"\\nDataset: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "\n",
    "    # Preprocessing\n",
    "    df.replace('#BOŞ!', np.nan, inplace=True)\n",
    "    \n",
    "    for col in ['KTAS duration_min', 'Length of stay_min']:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    df['Chief_complain'] = df['Chief_complain'].fillna('')\n",
    "    df['severity_score'] = df['Chief_complain'].apply(calculate_severity_score)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != 'Chief_complain':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    df.dropna(subset=['KTAS_expert'], inplace=True)\n",
    "\n",
    "    # --- MERGE CLASS 4 AND 5 ---\n",
    "    print(\"\\nMerging KTAS classes 4 and 5 into a single class (4)...\")\n",
    "    df['KTAS_expert'] = df['KTAS_expert'].replace(5, 4)\n",
    "    \n",
    "    df = engineer_features(df)\n",
    "    \n",
    "    print(\"\\nNew Class Distribution:\")\n",
    "    for cls in sorted(df['KTAS_expert'].unique()):\n",
    "        count = (df['KTAS_expert'] == cls).sum()\n",
    "        print(f\"  KTAS {int(cls)}: {count:4d} ({count/len(df)*100:5.1f}%)\")\n",
    "    \n",
    "    # Features\n",
    "    numeric_features = [\n",
    "        'Age', 'Sex', 'Group', 'Arrival mode', 'Injury', 'Mental', \n",
    "        'Pain', 'NRS_pain', 'SBP', 'DBP', 'HR', 'RR', 'BT', 'Saturation',\n",
    "        'severity_score', 'shock_index', 'map', 'pulse_pressure',\n",
    "        'abnormal_vitals', 'severity_x_pain', 'severity_x_mental',\n",
    "        'age_x_severity', 'high_risk_age', 'high_pain'\n",
    "    ]\n",
    "    text_feature = 'Chief_complain'\n",
    "    target = 'KTAS_expert'\n",
    "\n",
    "    # Using a Pipeline to integrate preprocessing and classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_features),\n",
    "                ('text', TfidfVectorizer(stop_words='english'), text_feature)\n",
    "            ])),\n",
    "        ('classifier', XGBClassifier(\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss',\n",
    "            n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    # Split Data\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = (df[target].values - 1).astype(int) # 0-indexed for training (0,1,2,3)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Hyperparameter Grid for XGBoost\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [400, 500],\n",
    "        'classifier__max_depth': [5, 7],\n",
    "        'classifier__learning_rate': [0.05, 0.1],\n",
    "        'classifier__subsample': [0.8, 1.0],\n",
    "        'classifier__colsample_bytree': [0.8, 1.0],\n",
    "        'preprocessor__text__max_features': [250, None]\n",
    "    }\n",
    "\n",
    "    # GridSearchCV with standard F1-weighted scoring to find the best overall model\n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(\"TUNING XGBOOST FOR BEST OVERALL F1-SCORE\")\n",
    "    print(\"=\"*75)\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='f1_weighted', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Predict with the best model found\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred_proba = best_model.predict_proba(X_test)\n",
    "    \n",
    "    # --- APPLY CUSTOM THRESHOLD FOR PREDICTION ---\n",
    "    print(\"\\nApplying custom prediction threshold for KTAS 1...\")\n",
    "    # This threshold makes the model more sensitive to predicting class 0 (KTAS 1)\n",
    "    custom_thresholds = {0: 0.22} # If prob for KTAS 1 is > 30%, predict KTAS 1\n",
    "    y_pred = predict_with_thresholds(y_pred_proba, custom_thresholds)\n",
    "    \n",
    "    # --- Results Section ---\n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(\"FINAL RESULTS (WITH THRESHOLD TUNING)\")\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"\\n{'Metric':<25} {'Score':<15}\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"{'Accuracy':<25} {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"{'F1-Score (Weighted)':<25} {f1_weighted:.4f}\")\n",
    "    print(f\"{'F1-Score (Macro)':<25} {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"-\"*75)\n",
    "    target_names = [f\"KTAS {i}\" for i in range(1, 5)] # Now 4 classes\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    print(\"CONFUSION MATRIX\")\n",
    "    print(\"-\"*75)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    classes = sorted(np.unique(y_test))\n",
    "    \n",
    "    print(\"\\n          Predicted KTAS\")\n",
    "    print(\"Actual    \", \"   \".join([f\"{int(c)+1:3d}\" for c in classes]))\n",
    "    print(\"----------------------------------------\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        print(f\" KTAS {int(cls)+1}  {cm[i]}\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    if 'xgboost' in str(e):\n",
    "        print(\"\\nERROR: XGBoost not found. Please install it by running: pip install xgboost\")\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8603b95-f510-4cb6-a056-8c88b065fc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        right ocular pain\n",
       "1       right forearm burn\n",
       "2             arm pain, Lt\n",
       "3          ascites tapping\n",
       "4          distension, abd\n",
       "               ...        \n",
       "1262         mental change\n",
       "1263               dysuria\n",
       "1264             dizziness\n",
       "1265    Sensory, Decreased\n",
       "1266             orthopnea\n",
       "Name: Chief_complain, Length: 1267, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Chief_complain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad9614-1938-4e01-a243-64aaf901b2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor2",
   "language": "python",
   "name": "tensor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
